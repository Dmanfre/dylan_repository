dmv_foods_combined %>%
filter(entity_type == "ORG") %>%
group_by(recipient_name) %>%
summarize(total = sum(disbursement_amount)) %>%
arrange(desc(total))
library(tidyverse)
matches_2022 <- read_csv("https://raw.githubusercontent.com/dwillis/NCAAWomensSoccerData/main/data/ncaa_womens_soccer_matchstats_2022.csv")
head(matches_2022)
glimpse(matches_2022)
matches_2022 %>%
filter(team == "Maryland Terrapins, Terps") %>%
group_by(team) %>%
summarize(total_shots = sum(sh_att), total_quality_shots = sum(so_g)) %>%
mutate(percentage_quality_shots = (total_quality_shots/total_shots)*100) %>%
filter(total_shots > 50) %>%
arrange(desc(percentage_quality_shots))
matches_2021 <- read_csv("https://raw.githubusercontent.com/dwillis/NCAAWomensSoccerData/main/data/ncaa_womens_soccer_matchstats_2021.csv")
matches_2021 %>%
filter(team == "Maryland Terrapins, Terps", date < "2021-09-05") %>%
summarize(total_shots = sum(sh_att), total_shots_on_goal = sum(so_g)) %>%
mutate(sh_pct = total_shots_on_goal / total_shots)
matches_2022 %>%
filter(outcome == "Draw") %>%
group_by(team) %>%
summarise(total_ties = n()) %>%
filter(total_ties == 4 ) %>%
arrange(desc(total_ties))
matches_2022 %>%
filter(team == "Maryland Terrapins, Terps") %>%
group_by(team) %>%
summarize(total_corners = sum(corners), opp_corners = sum(defensive_corners)) %>%
mutate(difference = total_corners - opp_corners)
matches_2022 %>%
group_by(team) %>%
summarize(total_corners = sum(corners), opp_corners = sum(defensive_corners)) %>%
mutate(difference = total_corners - opp_corners) %>%
arrange(desc(difference))
matches_2023 <- read_csv("https://raw.githubusercontent.com/dwillis/NCAAWomensSoccerData/main/data/ncaa_womens_soccer_matchstats_2023.csv")
rm(list = "matches_2021")
View(matches_2022)
View(matches_2023)
matches_2022 <- matches_2022 %>%
mutate(total_goals = goals + defensive_goals)
matches_2023 <- matches_2023 %>%
mutate(total_goals = goals + defensive_goals)
matches_2022 <- matches_2022 %>%
mutate(total_goals = goals + defensive_goals)
matches_2023 <- matches_2023 %>%
mutate(total_goals = goals + defensive_goals)
t.test(matches_2022$total_goals, matches_2023$total_goals)
matches_2022_early <- matches_2022 %>%
filter(date < "2022-09-14")
t.test(matches_2022_early$total_goals, matches_2023$total_goals)
View(dmv_foods_combined)
dmv_foods_combined %>%
group_by(recipient_name) %>%
filter(entity_type == "ORG")
dmv_foods_combined %>%
group_by(recipient_name, disbursement_description) %>%
filter(entity_type == "ORG")
dmv_foods_combined %>%
group_by(recipient_name, disbursement_description) %>%
filter(entity_type == "ORG") %>%
select(recipient_name, disbursement_description, entity_type)
library(tidyverse)
install_github("dwillis/SportsDataTutorials" force=TRUE)
install_github("dwillis/SportsDataTutorials", force=TRUE)
install_github("dwillis/SportsDataTutorials",force=TRUE)
install_github("dwillis/SportsDataTutorials", force=TRUE)
library(devtools)
install_github("dwillis/SportsDataTutorials", force=TRUE)
knitr::opts_chunk$set(echo = TRUE)
#libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
#install.packages("ipumsr")
library(ipumsr)
dmv_foods_combined <- tibble()
# Define a list of years
cycles <- c('1112', '1314', '1516','1718','1920','2122','2324')
# need to build the path to the .txt file
path <- paste0("~/Downloads/data", cycle,".txt")
# Define a list of years
cycles <- c('1112', '1314', '1516','1718','1920','2122','2324')
column_names <- c("committee_id", "amndt_ind", "report_year", "report_type", "image_number", "line_number", "form_tp_cd", "sched_tp_cd", "recipient_name", "recipient_city", "recipient_state", "zip_code", "disbursement_date", "disbursement_amount", "transaction_pgi", "disbursement_description", "category", "category_desc", "memo_cd", "memo_text", "entity_type", "sub_id", "file_num", "tran_id", "back_ref_tran_id")  # Add your column names here
#search_terms to use in the loops and in each dataset
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")
# need to build the path to the .txt file
path <- paste0("~/Downloads/data", cycle,".txt")
# Define a list of years
cycles <- c('1112', '1314', '1516','1718','1920','2122','2324')
# Create a for loop to execute functions
for (cycle in cycles) {
# need to build the path to the .txt file
path <- paste0("~/Downloads/data", cycle,".txt")
print(path)
dmv_food <- read_delim(path, delim = "|", col_names = column_names)
dmv_food_filtered <- dmv_food %>%
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA") %>%
filter(entity_type != "IND") %>%
mutate(zip_code = str_sub(zip_code, start=1L, end=5L)) %>%
mutate(disbursement_date=mdy(disbursement_date)) %>%
filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
dmv_foods_combined <- bind_rows(dmv_foods_combined, dmv_food_filtered)
}
district_cols_cleaned <- read_csv("data/recipient_names_cleaned.csv")
district_cols_cleaned %>%
group_by(cleaned_names) %>%
count() %>%
arrange(n)
View(district_cols_cleaned)
district_cols_cleaned %>%
group_by(recipient_name, disbursement_description)
i
dmv_foods_combined %>%
group_by(recipient_name, disbursement_description)
dmv_foods_combined %>%
group_by(recipient_name, disbursement_description) %>%
select(recipient_name, disbursement_description)
dmv_foods_combined %>%
distinct(recipient_name) %>%
group_by(recipient_name, disbursement_description) %>%
select(recipient_name, disbursement_description)
dmv_foods_combined %>%
distinct(recipient_name, disbursement_description)
names_and_descriptions <- dmv_foods_combined %>%
distinct(recipient_name, disbursement_description)
#names_and_descriptions <-
dmv_foods_combined %>%
distinct(recipient_name, disbursement_description) %>%
mutate(cleaned_names = recipient_name)
#names_and_descriptions <-
dmv_foods_combined %>%
mutate(cleaned_names = recipient_name)
#names_and_descriptions <-
dmv_foods_combined %>%
distinct(recipient_name, disbursement_description) %>%
mutate(cleaned_names = recipient_name)
knitr::opts_chunk$set(echo = TRUE)
#libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
#install.packages("ipumsr")
library(ipumsr)
knitr::opts_chunk$set(echo = TRUE)
wbb_rosters_22_23 %>%
filter(is.NA(state_clean)) %>%
group_by(state_clean) %>%
count()
#libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
#install.packages("ipumsr")
library(ipumsr)
#Loading in the data from 22-23 season
wbb_rosters_22_23 <- read_csv("data/wbb_rosters_2022_23.csv")
head(wbb_rosters_22_23)
wbb_rosters_22_23 %>%
filter(is.NA(state_clean)) %>%
group_by(state_clean) %>%
count()
wbb_rosters_22_23 %>%
filter(is.na(state_clean)) %>%
group_by(state_clean) %>%
count()
wbb_rosters_22_23 %>%
filter(is.na(state_clean))
#One thought I had would be to export the cleaned_nammes but put the disbursement_description next to it so we can see the reason for the transaction. I think this would help understand what was really used for a food expense and what was not. I commented out what I think the code should look like.
#names_and_descriptions <-
dmv_foods_combined %>%
distinct(recipient_name, disbursement_description) %>%
mutate(cleaned_names = recipient_name)
#establishing column names and search terms to use in each dataset
column_names <- c("committee_id", "amndt_ind", "report_year", "report_type", "image_number", "line_number", "form_tp_cd", "sched_tp_cd", "recipient_name", "recipient_city", "recipient_state", "zip_code", "disbursement_date", "disbursement_amount", "transaction_pgi", "disbursement_description", "category", "category_desc", "memo_cd", "memo_text", "entity_type", "sub_id", "file_num", "tran_id", "back_ref_tran_id")  # Add your column names here
#search_terms to use in the loops and in each dataset
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")
#establishing and trying out things for the loop
dmv_foods_combined <- tibble()
# Define a list of years
cycles <- c('1112', '1314', '1516','1718','1920','2122','2324')
# Create a for loop to execute functions
for (cycle in cycles) {
# need to build the path to the .txt file
path <- paste0("~/Downloads/data", cycle,".txt")
print(path)
dmv_food <- read_delim(path, delim = "|", col_names = column_names)
dmv_food_filtered <- dmv_food %>%
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA") %>%
filter(entity_type != "IND") %>%
mutate(zip_code = str_sub(zip_code, start=1L, end=5L)) %>%
mutate(disbursement_date=mdy(disbursement_date)) %>%
filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
dmv_foods_combined <- bind_rows(dmv_foods_combined, dmv_food_filtered)
}
# fix the dates that havent happened yet and I can do that by looking at the image number on FEC.
# FOR OPEN REFINE I WANT A LIST OF UNIQUE RESTURANTS.
#RETAIN HOW IT ORIGINALLY APPEARS AND THEN MAKE A COPY OF THE COLUMN.
write_csv(dmv_foods_combined, "data/dmv_foods_combined.csv")
#What are the entity types
dmv_foods_combined %>%
group_by(entity_type) %>%
count()
#ORG has the most with 208,760 transactions. Need to see what types of places make up that entity_type column.
dmv_foods_combined %>%
filter(entity_type == "ORG") %>%
group_by(recipient_name) %>%
summarize(total = sum(disbursement_amount)) %>%
arrange(desc(total))
#This is showing that not many of the top recipients in the ORG category are actual food establishments
#Creating a column of the recipients to be cleaned in Open Refine
distinct_columns <- dmv_foods_combined %>%
distinct(recipient_name) %>%
mutate(cleaned_names = recipient_name)
write_csv(distinct_columns, "data/distinct_columns.csv")
#reading back the cleaned district columns
district_cols_cleaned <- read_csv("data/recipient_names_cleaned.csv")
district_cols_cleaned %>%
group_by(cleaned_names) %>%
count() %>%
arrange(n)
#Methodology: brought back the cleaned district columns after standardizing and clustering in open refine. I put a Y in a "exclude" column because those recipient names are not related to food or food establishments. One method of getting rid of those names was doing that. Another is joining the district_cols_cleaned dataframe back to dmv_foods_combined and then filtering out everything that is not an ORG entity_type
#Trying to see what type of places are in the other categories in Entity_type. This will help. determine more I should exclude in Google Sheets. From there, I can gather more key words to label Y when I exclude them later on.
dmv_foods_combined %>%
group_by(recipient_name, disbursement_description) %>%
filter(entity_type == "ORG") %>%
select(recipient_name, disbursement_description, entity_type)
# In addition to cleaning the names in sheets, I think a good way to find out what I need to exclude is by looking at the disbursement description. Because I don't want transactions that ahve to do with general committee stuff or meetings. I want places where they actually spend money on food.
#One thought I had would be to export the cleaned_nammes but put the disbursement_description next to it so we can see the reason for the transaction. I think this would help understand what was really used for a food expense and what was not. I commented out what I think the code should look like.
#names_and_descriptions <-
dmv_foods_combined %>%
distinct(recipient_name, disbursement_description) %>%
mutate(cleaned_names = recipient_name)
#group_by(recipient_name, disbursement_description) %>%
#select(recipient_name, disbursement_description)
wbb_rosters_22_23 %>%
filter(is.na(state_clean))
wbb_rosters_22_23 %>%
wbb_rosters_22_23 %>%
wbb_rosters_22_23 %>%
group_by(conference) %>%
count()%>%
arrange(desc(n)
wbb_rosters_22_23 %>%
wbb_rosters_22_23 %>%
group_by(conference) %>%
count() %>%
arrange(desc(n))
power_five <- c("Big Ten", "SEC", "Big 12", "Pac-12", "ACC")
wbb_rosters_22_23 %>%
filter(power_five)
wbb_rosters_22_23 %>%
filter(conference = power_five)
wbb_rosters_22_23 %>%
filter(conference == power_five)
#This code was created organically and not by chatgpt
wbb_rosters_22_23 %>%
filter(conference == power_five)
wbb_rosters_22_23 %>%
filter(conference == power_five, state == "MD")
wbb_rosters_22_23 %>%
filter(conference == power_five, homestate == "MD")
2
wbb_rosters_22_23 %>%
filter(conference == power_five | homestate == "MD")
wbb_rosters_22_23 %>%
filter(conference == power_five | homestate == "Maryland")
r
wbb_rosters_22_23 %>%
filter(conference == power_five) %>%
filter(homestate == "Maryland")
wbb_rosters_22_23 %>%
filter(homestate == "Maryland")
wbb_rosters_22_23 %>%
filter(homestate == "Maryland") %>%
group_by(team)
#This code was created organically and not by chatgpt
wbb_rosters_22_23 %>%
filter(conference == power_five | homestate == "Maryland")
#This code was created organically and not by chatgpt
wbb_rosters_22_23 %>%
filter(conference == power_five,  homestate == "Maryland")
#This code was created organically and not by chatgpt
wbb_rosters_22_23 %>%
filter(conference == power_five | homestate == "Maryland")
#This code was created organically and not by chatgpt
wbb_rosters_22_23 %>%
filter(conference == power_five & homestate == "Maryland")
#This code was created organically and not by chatgpt
wbb_rosters_22_23 %>%
filter(conference == power_five)
wbb_rosters_22_23 %>%
filter(conference == power_five, homestate == "Maryland")
wbb_rosters_22_23 %>%
filter(conference == power_five, homestate == "Maryland")
#filtering for power 5 and people from maryland
wbb_rosters_22_23 %>%
filter(conference == power_five, state_clean == "MD")
wbb_rosters_22_23 %>%
group_by(state_clean) %>%
filter(state_clean == "MD") %>%
count()
wbb_rosters_22_23 %>%
group_by(state_clean) %>%
count() %>%
arrange(desc(n))
wbb_rosters_22_23 %>%
filter(state_clean == "MD") %>%
filter(conference == power_five)
wbb_rosters_22_23 %>%
filter(state_clean == "MD")
from_maryland <-  wbb_rosters_22_23 %>%
filter(state_clean == "MD")
View(from_maryland)
#filtering for power 5 and people from maryland
wbb_rosters_22_23 %>%
filter(conference == power_five, state_clean == "MD")
power_five
wbb_rosters_22_23 %>%
filter(Conference %in% powerfive)
wbb_rosters_22_23 %>%
filter(conference %in% powerfive)
wbb_rosters_22_23 %>%
filter(conference %in% power_five)
wbb_rosters_22_23 %>%
filter(conference %in% power_five | homestate == "MD")
wbb_rosters_22_23 %>%
filter(conference %in% power_five) %>%
filter(state_clean == "MD")
wbb_rosters_22_23 %>%
filter(conference %in% power_five) %>%
filter(state_clean == "MD") %>%
select(team, name, year, hometown, conference)
wbb_rosters_22_23 %>%
filter(conference %in% power_five) %>%
filter(state_clean == "MD")
wbb_rosters_22_23 %>%
filter(conference %in% power_five)
View(from_maryland)
from_maryland %>%
filter(conference %in% power_five)
from_maryland %>%
filter(conference %in% power_five) %>%
group_by(conference) %>%
count()
View(new_food_data)
knitr::opts_chunk$set(echo = TRUE)
# Libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
library(ipumsr)
library(usdata)
library(postmastr)
setwd("~/Documents/GitHub/dylan_repository")
setwd("~/Documents/GitHub/dylan_repository/wbb_roster_23_24")
#libraries
library(tidyverse)
library(janitor)
rosters_23_24 <- read_csv("data/rosters_23_24.csv")
rosters_23_24 <- read_csv("data/rosters-23-24.csv")
rosters_23_24 <- read_csv("data/rosters-23-24.csv")
rosters_23_24 <- read_csv("data/rosters_2023-24.csv")
View(rosters_23_24)
#height cleaning
rosters_23_24 <- rosters_23_24 %>%
mutate(height_clean = str_replace(height, "'", '-')) %>%
mutate(height_clean = str_replace(height_clean, "’", '-')) %>%
mutate(height_clean = str_replace(height_clean, "''", '')) %>%
mutate(height_clean = str_replace(height_clean, '"', '')) %>%
separate(height_clean, c('height_ft', 'height_in'), sep="-", extra="merge") %>%
mutate(height_ft = as.numeric(height_ft), height_in = as.numeric(height_in)) %>%
mutate(total_inches = (height_ft*12)+height_in)
rosters_23_24 %>%
group_by(total_inches) %>%
summarise(
total = n()
)
wbb_rosters23 %>% filter(is.na(total_inches)) %>% group_by(team) %>% summarize(count = n()) %>% arrange(desc(count))
rosters_23_24 %>% filter(is.na(total_inches)) %>% group_by(team) %>% summarize(count = n()) %>% arrange(desc(count))
rosters_23_24 %>%
mutate(height_clean = str_replace(height, "'", '-')) %>%
mutate(height_clean = str_replace(height_clean, "’", '-')) %>%
mutate(height_clean = str_replace(height_clean, "''", '')) %>%
mutate(height_clean = str_replace(height_clean, '"', '')) %>%
separate(height_clean, c('height_ft', 'height_in'), sep="-", extra="merge") %>%
mutate(height_ft = as.numeric(height_ft), height_in = as.numeric(height_in)) %>%
mutate(total_inches = (height_ft*12)+height_in)
rosters_23_24 <- read_csv("data/rosters_2023-24.csv")
#height cleaning
rosters_23_24 <- rosters_23_24 %>%
mutate(height_clean = str_replace(height, "'", '-')) %>%
mutate(height_clean = str_replace(height_clean, "’", '-')) %>%
mutate(height_clean = str_replace(height_clean, "''", '')) %>%
mutate(height_clean = str_replace(height_clean, '"', '')) %>%
separate(height_clean, c('height_ft', 'height_in'), sep="-", extra="merge") %>%
mutate(height_ft = as.numeric(height_ft), height_in = as.numeric(height_in)) %>%
mutate(total_inches = (height_ft*12)+height_in)
rosters_23_24 %>%
filter(is.na(height))
# Previous school cleaning
rosters_23_24 %>%
filter(is.na(high_school))%>%
filter(!is.na(previous_school))%>%
filter(str_detect(previous_school, "HS"))%>%
mutate(hs_clean = "")%>%
mutate(hs_clean = previous_school)%>%
mutate(type = "has hs")
rosters_23_24 %>%
filter(is.na(high_school))%>%
filter(!is.na(previous_school))%>%
filter(str_detect(previous_school, "HS"))%>%
mutate(hs_clean = "")
rosters_23_24 %>%
filter(is.na(high_school))%>%
filter(!is.na(previous_school))%>%
filter(str_detect(previous_school, "HS"))%>%
mutate(hs_clean = "") %>%
mutate(hs_clean = previous_school)
rosters_23_24 %>%
filter(is.na(high_school))%>%
filter(!is.na(previous_school))%>%
filter(str_detect(previous_school, "HS"))%>%
mutate(hs_clean = "") %>%
mutate(hs_clean = previous_school) %>%
mutate(type = "has hs")
# Previous school cleaning
rosters_23_24 <- rosters_23_24 %>%
filter(is.na(high_school))%>%
filter(!is.na(previous_school))%>%
filter(str_detect(previous_school, "HS"))%>%
mutate(hs_clean = "") %>%
mutate(hs_clean = previous_school) %>%
mutate(type = "has hs")
rosters_23_24 %>%
filter(!is.na(high_school))%>%
filter(is.na(previous_school))%>%
mutate(hs_clean = "")%>%
mutate(type = "no hs")
rosters_23_24 <- read_csv("data/rosters_2023-24.csv")
#height cleaning
rosters_23_24 <- rosters_23_24 %>%
mutate(height_clean = str_replace(height, "'", '-')) %>%
mutate(height_clean = str_replace(height_clean, "’", '-')) %>%
mutate(height_clean = str_replace(height_clean, "''", '')) %>%
mutate(height_clean = str_replace(height_clean, '"', '')) %>%
separate(height_clean, c('height_ft', 'height_in'), sep="-", extra="merge") %>%
mutate(height_ft = as.numeric(height_ft), height_in = as.numeric(height_in)) %>%
mutate(total_inches = (height_ft*12)+height_in)
rosters_23_24 %>%
filter(is.na(height))
# Previous school cleaning
hs_wbb <- rosters_23_24 %>%
filter(is.na(high_school))%>%
filter(!is.na(previous_school))%>%
filter(str_detect(previous_school, "HS"))%>%
mutate(hs_clean = "") %>%
mutate(hs_clean = previous_school) %>%
mutate(type = "has hs")
extras_wbb <- rosters_23_24 %>%
filter(!is.na(high_school))%>%
filter(is.na(previous_school))%>%
mutate(hs_clean = "")%>%
mutate(type = "no hs")
all_wbb <- bind_rows(hs_wbb, extras_wbb)
previous_school_is_hs=as.list(hs_wbb$previous_school)
View(previous_school_is_hs)
rosters_23_24 <- rosters_23_24 %>%
mutate(hs_clean = case_when(
is.na(high_school) & previous_school %in% previous_school_is_hs ~ previous_school,
TRUE ~ high_school)
)
rosters_23_24 <- rosters_23_24 %>%
mutate(previous_school = ifelse(previous_school == hs_clean, NA, previous_school))
library(postmastr)
library(usdata)
fibaurl <- "https://www.fiba.basketball/rankingwomen"
nations <- fibaurl %>%
read_html() %>%
html_nodes(xpath = '//*[@id="fiba_ranking_table_wrapper"]/table') %>%
html_table()
library(rvest)
fibaurl <- "https://www.fiba.basketball/rankingwomen"
nations <- fibaurl %>%
read_html() %>%
html_nodes(xpath = '//*[@id="fiba_ranking_table_wrapper"]/table') %>%
html_table()
nations_df <- nations[[1]]
wbb_rosters23 <- mutate(wbb_rosters23, country = case_when(!is.na(pm.state) ~ "USA"))
View(nations_df)
View(nations_df)
added_nations <- data.frame(Worldrank=c(0, 0, 0, 0),
Country=c('ENGLAND', 'RUSSIA', 'SCOTLAND', 'NORTHERN IRELAND'),
Zonerank=c(0, 0, 0, 0),
IOC=c('', '', '', ''),
"Current points"=c(0, 0, 0, 0),
"+/- Rank *"=c(0, 0, 0, 0),
check.names = FALSE)
added_nations <- data.frame(Worldrank=c(0, 0, 0, 0),
Country=c('ENGLAND', 'RUSSIA', 'SCOTLAND', 'NORTHERN IRELAND'),
Zonerank=c(0, 0, 0, 0),
IOC=c('', '', '', ''),
"Current points"=c(0, 0, 0, 0),
"+/- Rank *"=c(0, 0, 0, 0),
check.names = FALSE)
View(added_nations)
